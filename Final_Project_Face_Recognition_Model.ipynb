{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Project_Face_Recognition_Model",
      "provenance": [],
      "authorship_tag": "ABX9TyMUoQUOi3odfkyz0m+Km6og",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wiiloebis/bangkit_machine_learning_assigment/blob/master/Final_Project_Face_Recognition_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91y9PVhu9Uwf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "e5e6575d-260a-409d-cb57-019bfa9fd4c8"
      },
      "source": [
        "#Pre setup\n",
        "# Download pre-trained FaceNet model that will be used for image embedding process\n",
        "! wget https://github.com/D2KLab/Face-Celebrity-Recognition/raw/master/model/facenet_keras.h5\n",
        "\n",
        "# install mtcnn\n",
        "! pip install mtcnn\n",
        "\n",
        "# to split folder into train/val dataset\n",
        "! pip install split-folders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-18 15:13:51--  https://github.com/D2KLab/Face-Celebrity-Recognition/raw/master/model/facenet_keras.h5\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/D2KLab/Face-Celebrity-Recognition/master/model/facenet_keras.h5 [following]\n",
            "--2020-06-18 15:13:52--  https://raw.githubusercontent.com/D2KLab/Face-Celebrity-Recognition/master/model/facenet_keras.h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 92397640 (88M) [application/octet-stream]\n",
            "Saving to: ‘facenet_keras.h5’\n",
            "\n",
            "facenet_keras.h5    100%[===================>]  88.12M  79.8MB/s    in 1.1s    \n",
            "\n",
            "2020-06-18 15:13:57 (79.8 MB/s) - ‘facenet_keras.h5’ saved [92397640/92397640]\n",
            "\n",
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n",
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/20/67/29dda743e6d23ac1ea3d16704d8bbb48d65faf3f1b1eaf53153b3da56c56/split_folders-0.3.1-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqnrwxQP-fCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "7e7c5c89-44ae-44e3-bc89-adc71faf7b22"
      },
      "source": [
        "#Import all the libs needed\n",
        "import mtcnn\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4b73c60ddf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Import all the libs needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmtcnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mtcnn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SocTbFBc90w3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing kaggle environment to download the dataset. FGor a referance of how to get kaggle.json, please see https://www.kaggle.com/general/74235\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload() # upload kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlVrAQ2_-RYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "daf26dcc-cbbe-417c-936a-32716a38a0c4"
      },
      "source": [
        "# Download and split the dataset into train/val dataset\n",
        "# The data set source https://www.kaggle.com/hereisburak/pins-face-recognition\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d hereisburak/pins-face-recognition\n",
        "! unzip pins-face-recognition.zip\n",
        "\n",
        "import split_folders\n",
        "training_examples = 30\n",
        "validation_examples = 10\n",
        "collection_dir = 'pins_dataset'\n",
        "\n",
        "split_folders.fixed(input='105_classes_pins_dataset', output=collection_dir, fixed=(training_examples, validation_examples))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "unzip:  cannot find or open pins-face-recognition.zip, pins-face-recognition.zip.zip or pins-face-recognition.zip.ZIP.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-08bc89dfd683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' unzip pins-face-recognition.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msplit_folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtraining_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mvalidation_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'split_folders'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6lDtrTjSsL3",
        "colab_type": "text"
      },
      "source": [
        "## Face Detection\n",
        "Purpose for this cell is to get a face only dataset from the given dataset, to be able to be used in face embedding process. The faces extracted will save all the detected face to faces-only-dataset.npz format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tNSPHGBTGNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_face(filename, required_size=(160,160)):\n",
        "    detector = MTCNN()\n",
        "    image = Image.open(filename)\n",
        "    image = image.convert('RGB')\n",
        "    pixels = asarray(image)\n",
        "    faces = detector.detect_faces(pixels)\n",
        "\n",
        "    face_array = None\n",
        "    if len(faces) > 0:\n",
        "      initialX, initialY, initialWidth, initialHeight = faces[0]['box']\n",
        "      used_index = 0\n",
        "      highestWidth = initialX\n",
        "      highestHeight = initialY\n",
        "      index = 0\n",
        "      for face in faces:\n",
        "      #With Assumption that we're going to close up the targetted person\n",
        "          x, y, width, height = face['box']\n",
        "          if width > highestWidth or height > highestHeight :\n",
        "              used_index = index\n",
        "              break\n",
        "\n",
        "          index = index + 1\n",
        "          \n",
        "      x1, y1, width, height = faces[used_index]['box']    \n",
        "      x1, y1 = abs(x1), abs(y1)\n",
        "      x2, y2 = x1 + width, y1 + height\n",
        "      face_boundary = pixels[y1:y2, x1:x2]\n",
        "      face_image = Image.fromarray(face_boundary)\n",
        "      face_image = face_image.resize(required_size)\n",
        "      face_array = asarray(face_image)\n",
        "      # print(used_index)\n",
        "      return face_array\n",
        "    else:\n",
        "      print(f'{filename} face cannot be detected')\n",
        "      plt.imshow(image)\n",
        "      plt.show()\n",
        "    return face_array\n",
        "\n",
        "def load_faces(directory):\n",
        "    faces = []\n",
        "    for filename in os.listdir(directory):\n",
        "      path = os.path.join(directory, filename)\n",
        "      face = extract_face(path)\n",
        "      if face is not None:\n",
        "        faces.append(face)\n",
        "    return faces\n",
        "\n",
        "def load_dataset(directory):\n",
        "    x, y = [], []\n",
        "    counter = 1\n",
        "    for subdir in os.listdir(directory):\n",
        "      path = os.path.join(directory, subdir + '/') # e.g: train/ben_afflect/\n",
        "      print(f'processing {path} ({counter} out of {len(os.listdir(directory))})...')\n",
        "      faces = load_faces(path)\n",
        "      labels = [subdir for i in range(len(faces))] # assign label to each face\n",
        "      x.extend(faces)\n",
        "      y.extend(labels)\n",
        "      print('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
        "      counter += 1\n",
        "    return asarray(x), asarray(y)\n",
        "\n",
        "train_dir = os.path.join(collection_dir, 'train')\n",
        "train_X, train_y = load_dataset(train_dir)\n",
        "print(train_X.shape, train_y.shape)\n",
        "val_dir = os.path.join(collection_dir, 'val')\n",
        "val_X, val_y = load_dataset(val_dir)\n",
        "print(val_X.shape, val_y.shape)\n",
        "np.savez_compressed('faces-only-dataset.npz', train_X, train_y, val_X, val_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rb3Lc14TUdN",
        "colab_type": "text"
      },
      "source": [
        "#Create Embedding for Each Face\n",
        "From the face generated earlier, we create an embedding of the face using FaceNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6_QziTxTjPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "data = np.load('faces-only-dataset.npz')\n",
        "train_X, train_y = data['arr_0'], data['arr_1']\n",
        "test_X, test_y = data['arr_2'], data['arr_3']\n",
        "print('Dataset: train=%d, test=%d' % (train_X.shape[0], test_X.shape[0]))\n",
        "print('Loaded: ', train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
        "\n",
        "model = load_model('facenet_keras.h5')\n",
        "print('Loaded Model')\n",
        "\n",
        "def get_embedding(model, face_pixels):\n",
        "    face_pixels = face_pixels.astype('float32')\n",
        "    mean, std = face_pixels.mean(), face_pixels.std()\n",
        "    face_pixels = (face_pixels - mean)/std\n",
        "    samples = np.expand_dims(face_pixels, axis=0)\n",
        "    y_hat = model.predict(samples) # get the embedding\n",
        "    return y_hat\n",
        "\n",
        "start = time.time()\n",
        "new_train_X = list()\n",
        "for face_pixels in train_X:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnew_train_X.extend(embedding)\n",
        " \n",
        "new_train_X = asarray(new_train_X)\n",
        "print(new_train_X.shape)\n",
        "\n",
        "new_test_X = list()\n",
        "for face_pixels in test_X:\n",
        "\tembedding = get_embedding(model, face_pixels)\n",
        "\tnew_test_X.extend(embedding)\n",
        "new_test_X = asarray(new_test_X)\n",
        "\n",
        "print(new_test_X.shape)\n",
        "end = time.time()\n",
        "print(f'End processing for {end - start} seconds')\n",
        "\n",
        "np.savez_compressed('faces-embeddings.npz', new_train_X, train_y, new_test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}